{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bfortuner/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import imp\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import utils.training as train_utils; imp.reload(train_utils)\n",
    "import utils.plot as plot_utils; imp.reload(plot_utils)\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH='data/'\n",
    "RESULTS_PATH='results/'\n",
    "WEIGHTS_PATH='models/'\n",
    "CAMVID_PATH=DATA_PATH+'CamVid/'\n",
    "PROJECT_NAME='tiramisu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FirstConvLayer**\n",
    "\n",
    "* 3x3 Conv2D (pad=, stride=, in_chans=3, out_chans=48)\n",
    "\n",
    "**DenseLayer**\n",
    "\n",
    "* BatchNorm\n",
    "* ReLU\n",
    "* 3x3 Conv2d (pad=, stride=, in_chans=, out_chans=) - \"no resolution loss\" - padding included\n",
    "* Dropout (.2)\n",
    "\n",
    "**DenseBlock**\n",
    "\n",
    "* Input = FirstConvLayer, TransitionDown, or TransitionUp\n",
    "* Loop to create L DenseLayers (L=n_layers)\n",
    "* On TransitionDown we Concat(Input, FinalDenseLayerActivation)\n",
    "* On TransitionUp we do not Concat with input, instead pass FinalDenseLayerActivation to TransitionUp block\n",
    "\n",
    "**TransitionDown**\n",
    "\n",
    "* BatchNorm\n",
    "* ReLU\n",
    "* 1x1 Conv2D (pad=, stride=, in_chans=, out_chans=)\n",
    "* Dropout (0.2)\n",
    "* 2x2 MaxPooling\n",
    "\n",
    "**Bottleneck**\n",
    "\n",
    "* DenseBlock (15 layers)\n",
    "\n",
    "**TransitionUp**\n",
    "\n",
    "* 3x3 Transposed Convolution (pad=, stride=2, in_chans=, out_chans=)\n",
    "* Concat(PreviousDenseBlock, SkipConnection) - from cooresponding DenseBlock on transition down\n",
    "\n",
    "**FinalBlock**\n",
    "\n",
    "* 1x1 Conv2d (pad=, stride=, in_chans=256, out_chans=n_classes)\n",
    "* Softmax\n",
    "\n",
    "**FCDenseNet103 Architecture**\n",
    "\n",
    "* input (in_chans=3 for RGB)\n",
    "* 3x3 ConvLayer (out_chans=48)\n",
    "* DB (4 layers) + TD\n",
    "* DB (5 layers) + TD\n",
    "* DB (7 layers) + TD\n",
    "* DB (10 layers) + TD\n",
    "* DB (12 layers) + TD\n",
    "* Bottleneck (15 layers)\n",
    "* TU + DB (12 layers)\n",
    "* TU + DB (10 layers)\n",
    "* TU + DB (7 layers)\n",
    "* TU + DB (5 layers)\n",
    "* TU + DB (4 layers)\n",
    "* 1x1 ConvLayer (out_chans=n_classes) n_classes=11 for CamVid\n",
    "* Softmax\n",
    "\n",
    "**FCDenseNet56**\n",
    "\n",
    "GrowthRate (k) = 12\n",
    "4 layers per dense block\n",
    "1 Conv Layer\n",
    "5 DenseBlocks Downsample (20 layers)\n",
    "5 TransitionDown\n",
    "4 Bottleneck layers\n",
    "5 Dense Blocks Upsample (20 layers)\n",
    "5 TransitionUp\n",
    "1 Conv Layer\n",
    "1 Softmax layer (doesn't count)\n",
    "56 Total layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.out_channels = in_channels + growth_rate\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "        #author's impl - lasange 'same' pads with half filter size (rounded down) on \"both\" sides\n",
    "        self.add_module('conv', nn.Conv2d(in_channels=in_channels, \n",
    "                out_channels=self.out_channels, kernel_size=3, stride=1, \n",
    "                  padding=3//2, bias=True))\n",
    "        \n",
    "        self.add_module('drop', nn.Dropout2d(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        return torch.cat([x, new_features], 1) # 1 = channel axis\n",
    "    \n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        n_channels = in_channels\n",
    "        for i in range(n_layers):\n",
    "            layer = DenseLayer(n_channels, growth_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "            n_channels += growth_rate\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    \n",
    "class TransitionDown(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(TransitionDown, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        #what is out_channels?\n",
    "        self.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=in_channels,\n",
    "                                          kernel_size=1, stride=1, padding=0, bias=True))\n",
    "        self.add_module('drop', nn.Dropout2d(0.2))\n",
    "        self.add_module('maxpool', nn.MaxPool2d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "class TransitionUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionUp, self).__init__()\n",
    "        self.add_module('transpose', nn.ConvTranspose2d(in_channels=in_channels, \n",
    "                           out_channels=out_channels, kernel_size=3, stride=2, \n",
    "                            padding=0, bias=True))\n",
    "        \n",
    "    def forward(self, x, skip_connection):\n",
    "        out = self.forward(x)\n",
    "        #l = ConcatLayer([l, skip_connection], cropping=[None, None, 'center', 'center'])\n",
    "        return torch.cat([out, skip_connection])\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.add_module('bottleneck', DenseBlock(in_channels, growth_rate, n_layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\n",
    "def he_uniform(weights):\n",
    "    pass\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        xavier(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FCDenseNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_blocks=5, layers_per_block=5, growth_rate=16, \n",
    "                 out_chans_first_conv=48, n_classes=11):\n",
    "        super(FCDenseNet, self).__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_channels = 0\n",
    "        \n",
    "        #####################\n",
    "        # First Convolution #\n",
    "        #####################\n",
    "        #W=HeUniform(gain='relu') ??\n",
    "        #pad='same'\n",
    "        self.firstConv = nn.Conv2d(in_channels=in_channels, \n",
    "                  out_channels=out_chans_first_conv, kernel_size=3, \n",
    "                  stride=1, padding=in_channels//2, bias=False)\n",
    "        self.n_channels += out_chans_first_conv\n",
    "        \n",
    "        #####################\n",
    "        # Downsampling path #\n",
    "        #####################\n",
    "        \n",
    "        skipConnectChannels = []\n",
    "        self.denseBlocksDown = []\n",
    "        self.transDownBlocks = []\n",
    "        for i in range(n_blocks):\n",
    "            db = DenseBlock(self.n_channels, growth_rate, layers_per_block)\n",
    "            self.add_module(\"DBDown%d\" % (i+1), db)\n",
    "            self.denseBlocksDown.append(db)\n",
    "            self.n_channels += (growth_rate*layers_per_block)\n",
    "            skipConnectChannels.insert(0, self.n_channels)\n",
    "            \n",
    "            td = TransitionDown(self.n_channels)\n",
    "            self.transDownBlocks.append(td)\n",
    "            self.add_module(\"TD%d\" % (i+1), td)\n",
    "            \n",
    "        #####################\n",
    "        #     Bottleneck    #\n",
    "        #####################\n",
    "        \n",
    "        self.bottleneck = Bottleneck(self.n_channels, growth_rate, layers_per_block)\n",
    "        prev_block_channels = growth_rate*layers_per_block\n",
    "        self.n_channels += prev_block_channels \n",
    "        \n",
    "        #######################\n",
    "        #   Upsampling path   #\n",
    "        #######################\n",
    "\n",
    "        self.transUpBlocks = []\n",
    "        self.denseBlocksUp = [] \n",
    "        for i in range(n_blocks):\n",
    "            tu = TransitionUp(self.n_channels, prev_block_channels + skipConnectChannels[i])\n",
    "            self.transUpBlocks.append(td)\n",
    "            self.add_module(\"TU%d\" % (i+1), tu)\n",
    "            \n",
    "            self.n_channels = prev_block_channels + skipConnectChannels[i]\n",
    "\n",
    "            db = DenseBlock(self.n_channels, growth_rate, layers_per_block)\n",
    "            self.denseBlocksUp.append(db)\n",
    "            self.add_module(\"DBUp%d\" % (i+1), db)\n",
    "\n",
    "            prev_block_channels = growth_rate*layers_per_block\n",
    "            self.n_channels += prev_block_channels\n",
    "            \n",
    "        #####################\n",
    "        #      Softmax      #\n",
    "        #####################\n",
    "        \n",
    "        self.finalConv = nn.Conv2d(in_channels=self.n_channels, out_channels=n_classes,\n",
    "                       kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.firstConv(x)\n",
    "        skip_connections = []\n",
    "        for i in range(self.n_blocks):\n",
    "            out = self.denseBlocksDown[i](out)\n",
    "            skip_connections.insert(0, out)\n",
    "            out = self.transDownBlocks[i](out)\n",
    "            \n",
    "        out = self.bottleneck(out)\n",
    "        \n",
    "        for i in range(self.n_blocks):\n",
    "            out = self.transDownBlocks[i](out, skip_connections[i]) \n",
    "            out = self.denseBlocksUp[i](out)\n",
    "        \n",
    "        out = self.finalConv(out)\n",
    "        # Reshape\n",
    "        batch_size = out.size()[0]\n",
    "        rows = out.size()[2]\n",
    "        cols = out.size()[3]\n",
    "        out = out.view(batch_size*row*cols, n_classes)\n",
    "        \n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = FCDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCDenseNet (\n",
      "  (firstConv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (DBDown1): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(80, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(96, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD1): TransitionDown (\n",
      "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown2): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(128, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(144, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(160, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(176, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(192, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD2): TransitionDown (\n",
      "    (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown3): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(208, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(224, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(240, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(272, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD3): TransitionDown (\n",
      "    (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown4): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(288, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(304, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(320, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(336, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(352, 368, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD4): TransitionDown (\n",
      "    (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(368, 368, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (DBDown5): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(368, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(384, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(400, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(416, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(432, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TD5): TransitionDown (\n",
      "    (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (conv): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (drop): Dropout2d (p=0.2)\n",
      "    (maxpool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (bottleneck): Bottleneck (\n",
      "    (bottleneck): DenseBlock (\n",
      "      (denselayer1): DenseLayer (\n",
      "        (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(448, 464, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer2): DenseLayer (\n",
      "        (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(464, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer3): DenseLayer (\n",
      "        (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(480, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer4): DenseLayer (\n",
      "        (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(496, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "      (denselayer5): DenseLayer (\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(512, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (drop): Dropout2d (p=0.2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (TU1): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(528, 528, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp1): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(528, 544, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(544, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(560, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(560, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(576, 592, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(592, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(592, 608, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU2): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(608, 448, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp2): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(448, 464, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(464, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(480, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(496, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(512, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU3): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(528, 368, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp3): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(368, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(384, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(400, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(416, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(432, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU4): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(448, 288, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp4): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(288, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(304, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(320, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(336, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(352, 368, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (TU5): TransitionUp (\n",
      "    (transpose): ConvTranspose2d(368, 208, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (DBUp5): DenseBlock (\n",
      "    (denselayer1): DenseLayer (\n",
      "      (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(208, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer2): DenseLayer (\n",
      "      (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(224, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer3): DenseLayer (\n",
      "      (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(240, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer4): DenseLayer (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "    (denselayer5): DenseLayer (\n",
      "      (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(272, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop): Dropout2d (p=0.2)\n",
      "    )\n",
      "  )\n",
      "  (finalConv): Conv2d(288, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (softmax): Softmax ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "* https://github.com/SimJeg/FC-DenseNet/blob/master/metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IoU(y_pred, y_true, n_classes, void_labels):\n",
    "    \"\"\"\n",
    "    Returns the intersection I and union U (to compute the jaccard I/U) and the accuracy.\n",
    "    :param y_pred: nd.array of predictions. shape  (b*0*1, c) with c = n_classes\n",
    "    :param y_true: groundtruth, shape  (b,0,1) or (b,c,0,1) with c=1\n",
    "    :param n_classes: int\n",
    "    :param void_labels: list of indexes of void labels\n",
    "    :return: return nd.array I and U of size (n_classes), and scalar acc\n",
    "    \"\"\"\n",
    "\n",
    "    # Put y_pred and y_true under the same shape\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = y_true.flatten()\n",
    "\n",
    "    # We use not_void in case the prediction falls in the void class of the groundtruth\n",
    "    not_void = ~ np.any([y_true == label for label in void_labels], axis=0)\n",
    "\n",
    "    I = np.zeros(n_classes)\n",
    "    U = np.zeros(n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        y_true_i = y_true == i\n",
    "        y_pred_i = y_pred == i\n",
    "\n",
    "        I[i] = np.sum(y_true_i & y_pred_i)\n",
    "        U[i] = np.sum((y_true_i | y_pred_i) & not_void)\n",
    "\n",
    "    accuracy = np.sum(I) / np.sum(not_void)\n",
    "    return I, U, accuracy\n",
    "\n",
    "def crossentropy(y_pred, y_true, void_labels):\n",
    "    # Flatten y_true\n",
    "    y_true = T.flatten(y_true)\n",
    "    \n",
    "    # Clip predictions\n",
    "\n",
    "    # Create mask\n",
    "    mask = T.ones_like(y_true)\n",
    "    for el in void_labels:\n",
    "        mask = T.switch(T.eq(y_true, el), np.int32(0), mask)\n",
    "\n",
    "    # Modify y_true temporarily\n",
    "    y_true_tmp = y_true * mask\n",
    "\n",
    "    # Compute cross-entropy\n",
    "    loss = T.nnet.categorical_crossentropy(y_pred, y_true_tmp)\n",
    "\n",
    "    # Compute masked mean loss\n",
    "    loss *= mask\n",
    "    loss = T.sum(loss) / T.sum(mask).astype('float32')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "* https://github.com/SimJeg/FC-DenseNet/blob/master/data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=3\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindir = os.path.join(CAMVID_PATH, 'train')\n",
    "valdir = os.path.join(CAMVID_PATH, 'val')\n",
    "testdir = os.path.join(CAMVID_PATH, 'test')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(traindir, transforms.Compose([\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize,\n",
    "    ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0001TP_006690.png',\n",
       " '0001TP_006720.png',\n",
       " '0001TP_006750.png',\n",
       " '0001TP_006780.png',\n",
       " '0001TP_006810.png',\n",
       " '0001TP_006840.png',\n",
       " '0001TP_006870.png',\n",
       " '0001TP_006900.png',\n",
       " '0001TP_006930.png',\n",
       " '0001TP_006960.png',\n",
       " '0001TP_006990.png',\n",
       " '0001TP_007020.png',\n",
       " '0001TP_007050.png',\n",
       " '0001TP_007080.png',\n",
       " '0001TP_007110.png',\n",
       " '0001TP_007140.png',\n",
       " '0001TP_007170.png',\n",
       " '0001TP_007200.png',\n",
       " '0001TP_007230.png',\n",
       " '0001TP_007260.png',\n",
       " '0001TP_007290.png',\n",
       " '0001TP_007320.png',\n",
       " '0001TP_007350.png',\n",
       " '0001TP_007380.png',\n",
       " '0001TP_007410.png',\n",
       " '0001TP_007440.png',\n",
       " '0001TP_007470.png',\n",
       " '0001TP_007500.png',\n",
       " '0001TP_007530.png',\n",
       " '0001TP_007560.png',\n",
       " '0001TP_007590.png',\n",
       " '0001TP_007620.png',\n",
       " '0001TP_007650.png',\n",
       " '0001TP_007680.png',\n",
       " '0001TP_007710.png',\n",
       " '0001TP_007740.png',\n",
       " '0001TP_007770.png',\n",
       " '0001TP_007800.png',\n",
       " '0001TP_007830.png',\n",
       " '0001TP_007860.png',\n",
       " '0001TP_007890.png',\n",
       " '0001TP_007920.png',\n",
       " '0001TP_007950.png',\n",
       " '0001TP_007980.png',\n",
       " '0001TP_008010.png',\n",
       " '0001TP_008040.png',\n",
       " '0001TP_008070.png',\n",
       " '0001TP_008100.png',\n",
       " '0001TP_008130.png',\n",
       " '0001TP_008160.png',\n",
       " '0001TP_008190.png',\n",
       " '0001TP_008220.png',\n",
       " '0001TP_008250.png',\n",
       " '0001TP_008280.png',\n",
       " '0001TP_008310.png',\n",
       " '0001TP_008340.png',\n",
       " '0001TP_008370.png',\n",
       " '0001TP_008400.png',\n",
       " '0001TP_008430.png',\n",
       " '0001TP_008460.png',\n",
       " '0001TP_008490.png',\n",
       " '0001TP_008520.png',\n",
       " '0006R0_f00930.png',\n",
       " '0006R0_f00960.png',\n",
       " '0006R0_f00990.png',\n",
       " '0006R0_f01020.png',\n",
       " '0006R0_f01050.png',\n",
       " '0006R0_f01080.png',\n",
       " '0006R0_f01110.png',\n",
       " '0006R0_f01140.png',\n",
       " '0006R0_f01170.png',\n",
       " '0006R0_f01200.png',\n",
       " '0006R0_f01230.png',\n",
       " '0006R0_f01260.png',\n",
       " '0006R0_f01290.png',\n",
       " '0006R0_f01320.png',\n",
       " '0006R0_f01350.png',\n",
       " '0006R0_f01380.png',\n",
       " '0006R0_f01410.png',\n",
       " '0006R0_f01440.png',\n",
       " '0006R0_f01470.png',\n",
       " '0006R0_f01500.png',\n",
       " '0006R0_f01530.png',\n",
       " '0006R0_f01560.png',\n",
       " '0006R0_f01590.png',\n",
       " '0006R0_f01620.png',\n",
       " '0006R0_f01650.png',\n",
       " '0006R0_f01680.png',\n",
       " '0006R0_f01710.png',\n",
       " '0006R0_f01740.png',\n",
       " '0006R0_f01770.png',\n",
       " '0006R0_f01800.png',\n",
       " '0006R0_f01830.png',\n",
       " '0006R0_f01860.png',\n",
       " '0006R0_f01890.png',\n",
       " '0006R0_f01920.png',\n",
       " '0006R0_f01950.png',\n",
       " '0006R0_f01980.png',\n",
       " '0006R0_f02010.png',\n",
       " '0006R0_f02040.png',\n",
       " '0006R0_f02070.png',\n",
       " '0006R0_f02100.png',\n",
       " '0006R0_f02130.png',\n",
       " '0006R0_f02160.png',\n",
       " '0006R0_f02190.png',\n",
       " '0006R0_f02220.png',\n",
       " '0006R0_f02250.png',\n",
       " '0006R0_f02280.png',\n",
       " '0006R0_f02310.png',\n",
       " '0006R0_f02340.png',\n",
       " '0006R0_f02370.png',\n",
       " '0006R0_f02400.png',\n",
       " '0006R0_f02430.png',\n",
       " '0006R0_f02460.png',\n",
       " '0006R0_f02490.png',\n",
       " '0006R0_f02520.png',\n",
       " '0006R0_f02550.png',\n",
       " '0006R0_f02580.png',\n",
       " '0006R0_f02610.png',\n",
       " '0006R0_f02640.png',\n",
       " '0006R0_f02670.png',\n",
       " '0006R0_f02700.png',\n",
       " '0006R0_f02730.png',\n",
       " '0006R0_f02760.png',\n",
       " '0006R0_f02790.png',\n",
       " '0006R0_f02820.png',\n",
       " '0006R0_f02850.png',\n",
       " '0006R0_f02880.png',\n",
       " '0006R0_f02910.png',\n",
       " '0006R0_f02940.png',\n",
       " '0006R0_f02970.png',\n",
       " '0006R0_f03000.png',\n",
       " '0006R0_f03030.png',\n",
       " '0006R0_f03060.png',\n",
       " '0006R0_f03090.png',\n",
       " '0006R0_f03120.png',\n",
       " '0006R0_f03150.png',\n",
       " '0006R0_f03180.png',\n",
       " '0006R0_f03210.png',\n",
       " '0006R0_f03240.png',\n",
       " '0006R0_f03270.png',\n",
       " '0006R0_f03300.png',\n",
       " '0006R0_f03330.png',\n",
       " '0006R0_f03360.png',\n",
       " '0006R0_f03390.png',\n",
       " '0006R0_f03420.png',\n",
       " '0006R0_f03450.png',\n",
       " '0006R0_f03480.png',\n",
       " '0006R0_f03510.png',\n",
       " '0006R0_f03540.png',\n",
       " '0006R0_f03570.png',\n",
       " '0006R0_f03600.png',\n",
       " '0006R0_f03630.png',\n",
       " '0006R0_f03660.png',\n",
       " '0006R0_f03690.png',\n",
       " '0006R0_f03720.png',\n",
       " '0006R0_f03750.png',\n",
       " '0006R0_f03780.png',\n",
       " '0006R0_f03810.png',\n",
       " '0006R0_f03840.png',\n",
       " '0006R0_f03870.png',\n",
       " '0006R0_f03900.png',\n",
       " '0006R0_f03930.png',\n",
       " '0016E5_00390.png',\n",
       " '0016E5_00420.png',\n",
       " '0016E5_00450.png',\n",
       " '0016E5_00480.png',\n",
       " '0016E5_00510.png',\n",
       " '0016E5_00540.png',\n",
       " '0016E5_00570.png',\n",
       " '0016E5_00600.png',\n",
       " '0016E5_00630.png',\n",
       " '0016E5_00660.png',\n",
       " '0016E5_00690.png',\n",
       " '0016E5_00720.png',\n",
       " '0016E5_00750.png',\n",
       " '0016E5_00780.png',\n",
       " '0016E5_00810.png',\n",
       " '0016E5_00840.png',\n",
       " '0016E5_00870.png',\n",
       " '0016E5_00901.png',\n",
       " '0016E5_00930.png',\n",
       " '0016E5_00960.png',\n",
       " '0016E5_00990.png',\n",
       " '0016E5_01020.png',\n",
       " '0016E5_01050.png',\n",
       " '0016E5_01080.png',\n",
       " '0016E5_01110.png',\n",
       " '0016E5_01140.png',\n",
       " '0016E5_01170.png',\n",
       " '0016E5_01200.png',\n",
       " '0016E5_01230.png',\n",
       " '0016E5_01260.png',\n",
       " '0016E5_01290.png',\n",
       " '0016E5_01320.png',\n",
       " '0016E5_01350.png',\n",
       " '0016E5_01380.png',\n",
       " '0016E5_01410.png',\n",
       " '0016E5_01440.png',\n",
       " '0016E5_01470.png',\n",
       " '0016E5_01500.png',\n",
       " '0016E5_01530.png',\n",
       " '0016E5_01560.png',\n",
       " '0016E5_01590.png',\n",
       " '0016E5_01620.png',\n",
       " '0016E5_01650.png',\n",
       " '0016E5_01680.png',\n",
       " '0016E5_01710.png',\n",
       " '0016E5_01740.png',\n",
       " '0016E5_01770.png',\n",
       " '0016E5_01800.png',\n",
       " '0016E5_01830.png',\n",
       " '0016E5_01860.png',\n",
       " '0016E5_01890.png',\n",
       " '0016E5_01920.png',\n",
       " '0016E5_01950.png',\n",
       " '0016E5_01980.png',\n",
       " '0016E5_02010.png',\n",
       " '0016E5_02040.png',\n",
       " '0016E5_02070.png',\n",
       " '0016E5_02100.png',\n",
       " '0016E5_02130.png',\n",
       " '0016E5_02160.png',\n",
       " '0016E5_02190.png',\n",
       " '0016E5_02220.png',\n",
       " '0016E5_02250.png',\n",
       " '0016E5_02280.png',\n",
       " '0016E5_02310.png',\n",
       " '0016E5_02340.png',\n",
       " '0016E5_02370.png',\n",
       " '0016E5_02400.png',\n",
       " '0016E5_04350.png',\n",
       " '0016E5_04380.png',\n",
       " '0016E5_04410.png',\n",
       " '0016E5_04440.png',\n",
       " '0016E5_04470.png',\n",
       " '0016E5_04500.png',\n",
       " '0016E5_04530.png',\n",
       " '0016E5_04560.png',\n",
       " '0016E5_04590.png',\n",
       " '0016E5_04620.png',\n",
       " '0016E5_04650.png',\n",
       " '0016E5_04680.png',\n",
       " '0016E5_04710.png',\n",
       " '0016E5_04740.png',\n",
       " '0016E5_04770.png',\n",
       " '0016E5_04800.png',\n",
       " '0016E5_04830.png',\n",
       " '0016E5_04860.png',\n",
       " '0016E5_04890.png',\n",
       " '0016E5_04920.png',\n",
       " '0016E5_04950.png',\n",
       " '0016E5_04980.png',\n",
       " '0016E5_05010.png',\n",
       " '0016E5_05040.png',\n",
       " '0016E5_05070.png',\n",
       " '0016E5_05100.png',\n",
       " '0016E5_05130.png',\n",
       " '0016E5_05160.png',\n",
       " '0016E5_05190.png',\n",
       " '0016E5_05220.png',\n",
       " '0016E5_05250.png',\n",
       " '0016E5_05280.png',\n",
       " '0016E5_05310.png',\n",
       " '0016E5_05340.png',\n",
       " '0016E5_05370.png',\n",
       " '0016E5_05400.png',\n",
       " '0016E5_05430.png',\n",
       " '0016E5_05460.png',\n",
       " '0016E5_05490.png',\n",
       " '0016E5_05520.png',\n",
       " '0016E5_05550.png',\n",
       " '0016E5_05580.png',\n",
       " '0016E5_05610.png',\n",
       " '0016E5_05640.png',\n",
       " '0016E5_05670.png',\n",
       " '0016E5_05700.png',\n",
       " '0016E5_05730.png',\n",
       " '0016E5_05760.png',\n",
       " '0016E5_05790.png',\n",
       " '0016E5_05820.png',\n",
       " '0016E5_05850.png',\n",
       " '0016E5_05880.png',\n",
       " '0016E5_05910.png',\n",
       " '0016E5_05940.png',\n",
       " '0016E5_05970.png',\n",
       " '0016E5_06000.png',\n",
       " '0016E5_06030.png',\n",
       " '0016E5_06060.png',\n",
       " '0016E5_06090.png',\n",
       " '0016E5_06120.png',\n",
       " '0016E5_06150.png',\n",
       " '0016E5_06180.png',\n",
       " '0016E5_06210.png',\n",
       " '0016E5_06240.png',\n",
       " '0016E5_06270.png',\n",
       " '0016E5_06300.png',\n",
       " '0016E5_06330.png',\n",
       " '0016E5_06360.png',\n",
       " '0016E5_06390.png',\n",
       " '0016E5_06420.png',\n",
       " '0016E5_06450.png',\n",
       " '0016E5_06480.png',\n",
       " '0016E5_06510.png',\n",
       " '0016E5_06540.png',\n",
       " '0016E5_06570.png',\n",
       " '0016E5_06600.png',\n",
       " '0016E5_06630.png',\n",
       " '0016E5_06660.png',\n",
       " '0016E5_06690.png',\n",
       " '0016E5_06720.png',\n",
       " '0016E5_06750.png',\n",
       " '0016E5_06780.png',\n",
       " '0016E5_06810.png',\n",
       " '0016E5_06840.png',\n",
       " '0016E5_06870.png',\n",
       " '0016E5_06900.png',\n",
       " '0016E5_06930.png',\n",
       " '0016E5_06960.png',\n",
       " '0016E5_06990.png',\n",
       " '0016E5_07020.png',\n",
       " '0016E5_07050.png',\n",
       " '0016E5_07080.png',\n",
       " '0016E5_07110.png',\n",
       " '0016E5_07140.png',\n",
       " '0016E5_07170.png',\n",
       " '0016E5_07200.png',\n",
       " '0016E5_07230.png',\n",
       " '0016E5_07260.png',\n",
       " '0016E5_07290.png',\n",
       " '0016E5_07320.png',\n",
       " '0016E5_07350.png',\n",
       " '0016E5_07380.png',\n",
       " '0016E5_07410.png',\n",
       " '0016E5_07440.png',\n",
       " '0016E5_07470.png',\n",
       " '0016E5_07500.png',\n",
       " '0016E5_07530.png',\n",
       " '0016E5_07560.png',\n",
       " '0016E5_07590.png',\n",
       " '0016E5_07620.png',\n",
       " '0016E5_07650.png',\n",
       " '0016E5_07680.png',\n",
       " '0016E5_07710.png',\n",
       " '0016E5_07740.png',\n",
       " '0016E5_07770.png',\n",
       " '0016E5_07800.png',\n",
       " '0016E5_07830.png',\n",
       " '0016E5_07860.png',\n",
       " '0016E5_07890.png',\n",
       " '0016E5_07920.png',\n",
       " '0016E5_08190.png',\n",
       " '0016E5_08220.png',\n",
       " '0016E5_08250.png',\n",
       " '0016E5_08280.png',\n",
       " '0016E5_08310.png',\n",
       " '0016E5_08340.png',\n",
       " '0016E5_08370.png',\n",
       " '0016E5_08400.png',\n",
       " '0016E5_08430.png',\n",
       " '0016E5_08460.png',\n",
       " '0016E5_08490.png',\n",
       " '0016E5_08520.png',\n",
       " '0016E5_08550.png',\n",
       " '0016E5_08580.png',\n",
       " '0016E5_08610.png',\n",
       " '0016E5_08640.png']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "* https://discuss.pytorch.org/t/convert-pixel-wise-class-tensor-to-image-segmentation/1268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sky = [128,128,128]\n",
    "Building = [128,0,0]\n",
    "Pole = [192,192,128]\n",
    "Road_marking = [255,69,0]\n",
    "Road = [128,64,128]\n",
    "Pavement = [60,40,222]\n",
    "Tree = [128,128,0]\n",
    "SignSymbol = [192,128,128]\n",
    "Fence = [64,64,128]\n",
    "Car = [64,0,128]\n",
    "Pedestrian = [64,64,0]\n",
    "Bicyclist = [0,128,192]\n",
    "Unlabelled = [0,0,0]\n",
    "\n",
    "label_colours = np.array([Sky, Building, Pole, Road, Pavement,\n",
    "      Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "\n",
    "def visualize(temp, plot=True):\n",
    "    r = temp.copy()\n",
    "    g = temp.copy()\n",
    "    b = temp.copy()\n",
    "    for l in range(0,11):\n",
    "        r[temp==l]=label_colours[l,0]\n",
    "        g[temp==l]=label_colours[l,1]\n",
    "        b[temp==l]=label_colours[l,2]\n",
    "\n",
    "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
    "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
    "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
    "    if plot:\n",
    "        plt.imshow(rgb)\n",
    "    else:\n",
    "        return rgb\n",
    "    \n",
    "def imshow(inp):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)\n",
    "plt.title([dset_classes[x] for x in classes])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "* https://github.com/pytorch/examples/blob/master/imagenet/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**\n",
    "\n",
    "* WeightInitialization = HeUniform\n",
    "* Optimizer = RMSProp\n",
    "* LR = .001 with exponential decay of 0.995 after each epoch\n",
    "* Data Augmentation = Random Crops, Vertical Flips\n",
    "* ValidationSet with early stopping based on IoU or MeanAccuracy with patience of 100 (50 during finetuning)\n",
    "* WeightDecay = .0001\n",
    "* Finetune with full-size images, LR = .0001\n",
    "* Dropout = 0.2\n",
    "* BatchNorm \"we use current batch stats at training, validation, and test time\"\n",
    "\n",
    "**CamVid**\n",
    "\n",
    "* TrainingSet = 367 frames\n",
    "* ValidationSet = 101 frames\n",
    "* TestSet = 233 frames\n",
    "* Images of resolution 360x480\n",
    "* Images \"Cropped\" to 224x224 for training --- center crop?\n",
    "* FullRes images used for finetuning\n",
    "* NumberOfClasses = 11 (output)\n",
    "* BatchSize = 3\n",
    "\n",
    "**FCDenseNet103**\n",
    "\n",
    "* GrowthRate = 16 (k, number of filters to each denselayer adds to the ever-growing concatenated output)\n",
    "* No pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Decay LR by .995 every 1 epochs\"\"\"\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    lr *= (0.995 ** (epoch // 1))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust patience\n",
    "# https://github.com/SimJeg/FC-DenseNet/blob/master/train.py#L176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of params: 1059298\n",
      "Training new model from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train - Loss: 1.370707\tError: 43.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|| 1/1 [01:12<00:00, 72.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 1.3404, Error: 4590/10000 (46%)\n",
      "Time 1m 12s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "existing_weights_fpath=None\n",
    "nEpochs=1\n",
    "\n",
    "net = FCDenseNet(in_channels=3, n_blocks=5, layers_per_block=5, growth_rate=16, \n",
    "                 out_chans_first_conv=48, n_classes=11)\n",
    "net = net.cuda()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=.001, weight_decay=.0001)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "print('  + Number of params: {}'.format(\n",
    "    sum([p.data.nelement() for p in net.parameters()])))\n",
    "\n",
    "if existing_weights_fpath:\n",
    "    startEpoch = train_utils.load_weights(net, existing_weights_fpath)\n",
    "    endEpoch = startEpoch + nEpochs\n",
    "    print ('Resume training at epoch: {}'.format(startEpoch))\n",
    "    if os.path.exists(RESULTS_PATH+'train.csv'): #assume test.csv exists\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "    trainF = open(os.path.join(RESULTS_PATH, 'train.csv'), append_write)\n",
    "    testF = open(os.path.join(RESULTS_PATH, 'test.csv'), append_write)\n",
    "else:\n",
    "    print (\"Training new model from scratch\")\n",
    "    startEpoch = 1\n",
    "    endEpoch = nEpochs\n",
    "    trainF = open(os.path.join(RESULTS_PATH, 'train.csv'), 'w')\n",
    "    testF = open(os.path.join(RESULTS_PATH, 'test.csv'), 'w')\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(startEpoch, endEpoch+1)):\n",
    "    since = time.time()\n",
    "    train_utils.adjust_opt(\"sgd\", optimizer, epoch)\n",
    "    train_utils.train(epoch, net, trainLoader, optimizer, trainF)\n",
    "    train_utils.test(epoch, net, testLoader, optimizer, testF)\n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Time {:.0f}m {:.0f}s\\n'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    if epoch != 1:\n",
    "        os.system('./utils/plot.py {} &'.format(RESULTS_PATH))\n",
    "\n",
    "trainF.close()\n",
    "testF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
